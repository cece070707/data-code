{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fiscal-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.8/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/lib/python3.8/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk>=3.8->textblob) (4.55.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk>=3.8->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk>=3.8->textblob) (8.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk>=3.8->textblob) (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "isolated-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modified-twist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/datahub/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "# Natural Language Processing Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Additional Utilities\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Checking NLTK setup and downloaded resources\n",
    "nltk.download('popular')\n",
    "\n",
    "# Setup for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Print statement to confirm successful imports\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-quality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA Cardano - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>0.5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>0.5862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>0.5813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>0.5871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>0.5884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>0.4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>0.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>0.4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>11/04/2023 13:00</td>\n",
       "      <td>0.4084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime   Close\n",
       "0     11/04/2024 13:00  0.5835\n",
       "1     11/04/2024 12:00  0.5862\n",
       "2     11/04/2024 11:00  0.5813\n",
       "3     11/04/2024 10:00  0.5871\n",
       "4     11/04/2024 09:00  0.5884\n",
       "8779  11/04/2023 17:00  0.4020\n",
       "8780  11/04/2023 16:00  0.4003\n",
       "8781  11/04/2023 15:00  0.4055\n",
       "8782  11/04/2023 14:00  0.4040\n",
       "8783  11/04/2023 13:00  0.4084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BCH Bitcoin Cash - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>602.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>609.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>605.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>611.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>614.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>11/04/2023 18:00</td>\n",
       "      <td>129.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>129.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>129.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8292</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>128.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8293</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>128.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime   Close\n",
       "0     11/04/2024 13:00  602.88\n",
       "1     11/04/2024 12:00  609.78\n",
       "2     11/04/2024 11:00  605.63\n",
       "3     11/04/2024 10:00  611.00\n",
       "4     11/04/2024 09:00  614.02\n",
       "8289  11/04/2023 18:00  129.63\n",
       "8290  11/04/2023 17:00  129.36\n",
       "8291  11/04/2023 16:00  129.73\n",
       "8292  11/04/2023 15:00  128.97\n",
       "8293  11/04/2023 14:00  128.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BTC Bitcoin - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>70729.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>70856.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>70000.2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>70438.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>70597.4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>30234.4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>30154.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>30225.8525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>30086.3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>11/04/2023 13:00</td>\n",
       "      <td>30268.7250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime       Close\n",
       "0     11/04/2024 13:00  70729.9850\n",
       "1     11/04/2024 12:00  70856.4500\n",
       "2     11/04/2024 11:00  70000.2900\n",
       "3     11/04/2024 10:00  70438.0050\n",
       "4     11/04/2024 09:00  70597.4050\n",
       "8753  11/04/2023 17:00  30234.4575\n",
       "8754  11/04/2023 16:00  30154.8480\n",
       "8755  11/04/2023 15:00  30225.8525\n",
       "8756  11/04/2023 14:00  30086.3725\n",
       "8757  11/04/2023 13:00  30268.7250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETH Ethereum - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>3556.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>3557.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>3522.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>3560.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>3578.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>1907.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>1903.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>1915.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>1911.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>11/04/2023 13:00</td>\n",
       "      <td>1921.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime    Close\n",
       "0     11/04/2024 13:00  3556.00\n",
       "1     11/04/2024 12:00  3557.60\n",
       "2     11/04/2024 11:00  3522.23\n",
       "3     11/04/2024 10:00  3560.90\n",
       "4     11/04/2024 09:00  3578.10\n",
       "8763  11/04/2023 17:00  1907.80\n",
       "8764  11/04/2023 16:00  1903.45\n",
       "8765  11/04/2023 15:00  1915.31\n",
       "8766  11/04/2023 14:00  1911.70\n",
       "8767  11/04/2023 13:00  1921.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LTC Litecoin - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>95.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>96.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>95.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>96.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>96.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>94.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>94.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>95.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>94.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>11/04/2023 13:00</td>\n",
       "      <td>95.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime  Close\n",
       "0     11/04/2024 13:00  95.54\n",
       "1     11/04/2024 12:00  96.75\n",
       "2     11/04/2024 11:00  95.96\n",
       "3     11/04/2024 10:00  96.60\n",
       "4     11/04/2024 09:00  96.97\n",
       "8764  11/04/2023 17:00  94.92\n",
       "8765  11/04/2023 16:00  94.93\n",
       "8766  11/04/2023 15:00  95.30\n",
       "8767  11/04/2023 14:00  94.83\n",
       "8768  11/04/2023 13:00  95.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XRP Ripple - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/04/2024 13:00</td>\n",
       "      <td>0.60726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/04/2024 12:00</td>\n",
       "      <td>0.61397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/04/2024 11:00</td>\n",
       "      <td>0.60916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/04/2024 10:00</td>\n",
       "      <td>0.61388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/04/2024 09:00</td>\n",
       "      <td>0.61599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>11/04/2023 17:00</td>\n",
       "      <td>0.51457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>11/04/2023 16:00</td>\n",
       "      <td>0.51409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>11/04/2023 15:00</td>\n",
       "      <td>0.51959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>11/04/2023 14:00</td>\n",
       "      <td>0.51857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>11/04/2023 13:00</td>\n",
       "      <td>0.52324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DateTime    Close\n",
       "0     11/04/2024 13:00  0.60726\n",
       "1     11/04/2024 12:00  0.61397\n",
       "2     11/04/2024 11:00  0.60916\n",
       "3     11/04/2024 10:00  0.61388\n",
       "4     11/04/2024 09:00  0.61599\n",
       "8763  11/04/2023 17:00  0.51457\n",
       "8764  11/04/2023 16:00  0.51409\n",
       "8765  11/04/2023 15:00  0.51959\n",
       "8766  11/04/2023 14:00  0.51857\n",
       "8767  11/04/2023 13:00  0.52324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Telegram Sentiment - Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>views</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>binancesignals</td>\n",
       "      <td>1382</td>\n",
       "      <td>bitcoin market cap surpasses 13 trillion</td>\n",
       "      <td>04/03/2024 16:33</td>\n",
       "      <td>6319</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>binancesignals</td>\n",
       "      <td>1381</td>\n",
       "      <td>update atausdt long leverage cross x10 smashed...</td>\n",
       "      <td>04/03/2024 11:48</td>\n",
       "      <td>6847</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.751, 'pos': 0.249, 'comp...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binancesignals</td>\n",
       "      <td>1380</td>\n",
       "      <td>altcoins started make move bitcoin total marke...</td>\n",
       "      <td>03/03/2024 19:53</td>\n",
       "      <td>8066</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binancesignals</td>\n",
       "      <td>1379</td>\n",
       "      <td>coin maticusdt timeframe 1d observation broken...</td>\n",
       "      <td>03/03/2024 17:52</td>\n",
       "      <td>7740</td>\n",
       "      <td>{'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binancesignals</td>\n",
       "      <td>1378</td>\n",
       "      <td>coin aptusdt timeframe 1d observation broken m...</td>\n",
       "      <td>03/03/2024 17:50</td>\n",
       "      <td>7668</td>\n",
       "      <td>{'neg': 0.154, 'neu': 0.846, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14707</th>\n",
       "      <td>wolfoftrading</td>\n",
       "      <td>1184</td>\n",
       "      <td>ethusdt 1hr could possibly see continuation do...</td>\n",
       "      <td>04/12/2022 19:32</td>\n",
       "      <td>8927</td>\n",
       "      <td>{'neg': 0.159, 'neu': 0.771, 'pos': 0.07, 'com...</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14708</th>\n",
       "      <td>wolfoftrading</td>\n",
       "      <td>1183</td>\n",
       "      <td>egldusdt 1hr reaching first target broke raisi...</td>\n",
       "      <td>04/12/2022 19:14</td>\n",
       "      <td>8597</td>\n",
       "      <td>{'neg': 0.241, 'neu': 0.603, 'pos': 0.155, 'co...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14709</th>\n",
       "      <td>wolfoftrading</td>\n",
       "      <td>1182</td>\n",
       "      <td>first target reached 40 x20 leverage</td>\n",
       "      <td>03/12/2022 17:01</td>\n",
       "      <td>8540</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>wolfoftrading</td>\n",
       "      <td>1180</td>\n",
       "      <td>egldusdt formed adam eve bullish pattern plus ...</td>\n",
       "      <td>03/12/2022 12:03</td>\n",
       "      <td>8450</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td>wolfoftrading</td>\n",
       "      <td>1179</td>\n",
       "      <td>hello wolf first december week went profitable...</td>\n",
       "      <td>02/12/2022 14:16</td>\n",
       "      <td>8310</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.674, 'pos': 0.326, 'comp...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              channel    id  \\\n",
       "0      binancesignals  1382   \n",
       "1      binancesignals  1381   \n",
       "2      binancesignals  1380   \n",
       "3      binancesignals  1379   \n",
       "4      binancesignals  1378   \n",
       "14707   wolfoftrading  1184   \n",
       "14708   wolfoftrading  1183   \n",
       "14709   wolfoftrading  1182   \n",
       "14710   wolfoftrading  1180   \n",
       "14711   wolfoftrading  1179   \n",
       "\n",
       "                                                    text              date  \\\n",
       "0               bitcoin market cap surpasses 13 trillion  04/03/2024 16:33   \n",
       "1      update atausdt long leverage cross x10 smashed...  04/03/2024 11:48   \n",
       "2      altcoins started make move bitcoin total marke...  03/03/2024 19:53   \n",
       "3      coin maticusdt timeframe 1d observation broken...  03/03/2024 17:52   \n",
       "4      coin aptusdt timeframe 1d observation broken m...  03/03/2024 17:50   \n",
       "14707  ethusdt 1hr could possibly see continuation do...  04/12/2022 19:32   \n",
       "14708  egldusdt 1hr reaching first target broke raisi...  04/12/2022 19:14   \n",
       "14709               first target reached 40 x20 leverage  03/12/2022 17:01   \n",
       "14710  egldusdt formed adam eve bullish pattern plus ...  03/12/2022 12:03   \n",
       "14711  hello wolf first december week went profitable...  02/12/2022 14:16   \n",
       "\n",
       "       views                                             scores  compound  \\\n",
       "0       6319  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   \n",
       "1       6847  {'neg': 0.0, 'neu': 0.751, 'pos': 0.249, 'comp...    0.5106   \n",
       "2       8066  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   \n",
       "3       7740  {'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'comp...   -0.4767   \n",
       "4       7668  {'neg': 0.154, 'neu': 0.846, 'pos': 0.0, 'comp...   -0.4767   \n",
       "14707   8927  {'neg': 0.159, 'neu': 0.771, 'pos': 0.07, 'com...   -0.4215   \n",
       "14708   8597  {'neg': 0.241, 'neu': 0.603, 'pos': 0.155, 'co...   -0.2500   \n",
       "14709   8540  {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...    0.1027   \n",
       "14710   8450  {'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'comp...    0.4404   \n",
       "14711   8310  {'neg': 0.0, 'neu': 0.674, 'pos': 0.326, 'comp...    0.4404   \n",
       "\n",
       "      sentiment_type  \n",
       "0            NEUTRAL  \n",
       "1           POSITIVE  \n",
       "2            NEUTRAL  \n",
       "3           NEGATIVE  \n",
       "4           NEGATIVE  \n",
       "14707       NEGATIVE  \n",
       "14708       NEGATIVE  \n",
       "14709       POSITIVE  \n",
       "14710       POSITIVE  \n",
       "14711       POSITIVE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_path = '/files/Project/'\n",
    "\n",
    "# Load cryptocurrency data, skipping the first line and renaming the columns\n",
    "def load_crypto_data(file_path):\n",
    "    df = pd.read_csv(file_path, delimiter=';', decimal=',', skiprows=1)\n",
    "    df.rename(columns={df.columns[0]: 'DateTime', df.columns[1]: 'Close'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load Telegram data, skipping the first column\n",
    "def load_telegram_data(file_path):\n",
    "    df = pd.read_csv(file_path, delimiter=';', decimal=',')\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)  # Remove the first column\n",
    "    return df\n",
    "\n",
    "# Combine the first and last rows into a single DataFrame\n",
    "def combine_head_tail(df, num_rows=5):\n",
    "    return pd.concat([df.head(num_rows), df.tail(num_rows)])\n",
    "\n",
    "try:\n",
    "    ada_df = load_crypto_data(base_path + 'ADA_Cardano.csv')\n",
    "    bch_df = load_crypto_data(base_path + 'BCH_Bitcoin_cash.csv')\n",
    "    btc_df = load_crypto_data(base_path + 'BTC_Bitcoin.csv')\n",
    "    eth_df = load_crypto_data(base_path + 'ETH_Ethereum.csv')\n",
    "    ltc_df = load_crypto_data(base_path + 'LTC_Litecoin.csv')\n",
    "    xrp_df = load_crypto_data(base_path + 'XRP_Ripple.csv')\n",
    "    telegram_df = load_telegram_data(base_path + 'Telegram_sentiment.csv')\n",
    "\n",
    "    # Display combined data for each cryptocurrency\n",
    "    print(\"ADA Cardano - Data overview:\")\n",
    "    display(combine_head_tail(ada_df))\n",
    "    print(\"\\nBCH Bitcoin Cash - Data overview:\")\n",
    "    display(combine_head_tail(bch_df))\n",
    "    print(\"\\nBTC Bitcoin - Data overview:\")\n",
    "    display(combine_head_tail(btc_df))\n",
    "    print(\"\\nETH Ethereum - Data overview:\")\n",
    "    display(combine_head_tail(eth_df))\n",
    "    print(\"\\nLTC Litecoin - Data overview:\")\n",
    "    display(combine_head_tail(ltc_df))\n",
    "    print(\"\\nXRP Ripple - Data overview:\")\n",
    "    display(combine_head_tail(xrp_df))\n",
    "    \n",
    "    # Display combined data for Telegram Sentiment\n",
    "    print(\"\\nTelegram Sentiment - Data overview:\")\n",
    "    display(combine_head_tail(telegram_df))\n",
    "    \n",
    "except pd.errors.ParserError as e:\n",
    "    print(\"A parsing error occurred:\", e)\n",
    "except FileNotFoundError as e:\n",
    "    print(\"File not found:\", e)\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "french-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Setup and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-persian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (8.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.55.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/datahub/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/datahub/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers torch nltk pandas numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Downloading necessary datasets for nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focal-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(df, text_field):\n",
    "    # Ensure stopwords and lemmatizer are ready to be used\n",
    "    stop = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Convert all entries in the text field to string and handle NaN values\n",
    "    df[text_field] = df[text_field].fillna('').astype(str)\n",
    "    \n",
    "    # Lowercasing, removing stopwords, and lemmatization\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(\n",
    "        lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stop])\n",
    "    )\n",
    "    \n",
    "    # Removing special characters, ensuring to set regex=True for compatibility\n",
    "    df[text_field] = df[text_field].str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Use the function on your DataFrame\n",
    "telegram_df = clean_text(telegram_df, 'text')  # Using the actual name of the text column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "environmental-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Sentiment Analysis and Aspect Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fuzzy-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lasting-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554c88366999458d807e9fb5e046150b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2162f056f8bb4b15a414bea319b8d530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8908eebe79694f27881a3f5de1a8b9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564c2251c209493a99d9244686556321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e7426418eb4ea7ac190cc212a2ad0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the pre-trained model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "oriented-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the sentiment analysis function\n",
    "def sentiment_analysis(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.logits.argmax(-1).item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lined-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_df['sentiment'] = telegram_df['text'].apply(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "czech-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          channel    id                                               text  \\\n",
      "0  binancesignals  1382           bitcoin market cap surpasses 13 trillion   \n",
      "1  binancesignals  1381  update atausdt long leverage cross x10 smashed...   \n",
      "2  binancesignals  1380  altcoins started make move bitcoin total marke...   \n",
      "3  binancesignals  1379  coin maticusdt timeframe 1d observation broken...   \n",
      "4  binancesignals  1378  coin aptusdt timeframe 1d observation broken m...   \n",
      "\n",
      "               date  views                                             scores  \\\n",
      "0  04/03/2024 16:33   6319  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "1  04/03/2024 11:48   6847  {'neg': 0.0, 'neu': 0.751, 'pos': 0.249, 'comp...   \n",
      "2  03/03/2024 19:53   8066  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "3  03/03/2024 17:52   7740  {'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'comp...   \n",
      "4  03/03/2024 17:50   7668  {'neg': 0.154, 'neu': 0.846, 'pos': 0.0, 'comp...   \n",
      "\n",
      "   compound sentiment_type  sentiment  \n",
      "0    0.0000        NEUTRAL          1  \n",
      "1    0.5106       POSITIVE          2  \n",
      "2    0.0000        NEUTRAL          1  \n",
      "3   -0.4767       NEGATIVE          1  \n",
      "4   -0.4767       NEGATIVE          1  \n"
     ]
    }
   ],
   "source": [
    "print(telegram_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "jewish-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          channel    id                                               text  \\\n",
      "0  binancesignals  1382           bitcoin market cap surpasses 13 trillion   \n",
      "1  binancesignals  1381  update atausdt long leverage cross x10 smashed...   \n",
      "2  binancesignals  1380  altcoins started make move bitcoin total marke...   \n",
      "3  binancesignals  1379  coin maticusdt timeframe 1d observation broken...   \n",
      "4  binancesignals  1378  coin aptusdt timeframe 1d observation broken m...   \n",
      "\n",
      "               date  views                                             scores  \\\n",
      "0  04/03/2024 16:33   6319  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "1  04/03/2024 11:48   6847  {'neg': 0.0, 'neu': 0.751, 'pos': 0.249, 'comp...   \n",
      "2  03/03/2024 19:53   8066  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "3  03/03/2024 17:52   7740  {'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'comp...   \n",
      "4  03/03/2024 17:50   7668  {'neg': 0.154, 'neu': 0.846, 'pos': 0.0, 'comp...   \n",
      "\n",
      "   compound sentiment_type  sentiment  mismatch sentiment_label  \n",
      "0    0.0000        NEUTRAL          1     False         NEUTRAL  \n",
      "1    0.5106       POSITIVE          2     False        POSITIVE  \n",
      "2    0.0000        NEUTRAL          1     False         NEUTRAL  \n",
      "3   -0.4767       NEGATIVE          1      True         NEUTRAL  \n",
      "4   -0.4767       NEGATIVE          1      True         NEUTRAL  \n"
     ]
    }
   ],
   "source": [
    "# We define a dictionary to map the scores to textual labels\n",
    "sentiment_labels = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2: \"POSITIVE\"}\n",
    "\n",
    "# Next, we use 'map' with this dictionary to create the new column\n",
    "telegram_df['sentiment_label'] = telegram_df['sentiment'].map(sentiment_labels)\n",
    "\n",
    "print(telegram_df.head())\n",
    "\n",
    "telegram_df.to_csv(\"sentiment_analysis_with_labels.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "smoking-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of mismatches is 58.64%.\n"
     ]
    }
   ],
   "source": [
    "# Create a 'mismatch' column that is True when there is a discrepancy between the two columns\n",
    "telegram_df['mismatch'] = telegram_df['sentiment_type'].ne(telegram_df['sentiment_label'])\n",
    "\n",
    "# Count the total number of mismatches\n",
    "mismatches = telegram_df['mismatch'].sum()\n",
    "\n",
    "# Calculate the percentage of mismatches\n",
    "total_entries = len(telegram_df)\n",
    "percentage_mismatches = (mismatches / total_entries) * 100\n",
    "\n",
    "# Display the percentage of mismatches\n",
    "print(f\"The percentage of mismatches is {percentage_mismatches:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acoustic-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 'major errors' is 1.78%.\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to get only the rows where there is a \"major error\"\n",
    "major_errors_df = telegram_df[\n",
    "    (telegram_df['sentiment_type'] == \"POSITIVE\") & (telegram_df['sentiment_label'] == \"NEGATIVE\") |\n",
    "    (telegram_df['sentiment_type'] == \"NEGATIVE\") & (telegram_df['sentiment_label'] == \"POSITIVE\")\n",
    "]\n",
    "\n",
    "# Count the number of \"major errors\"\n",
    "number_major_errors = len(major_errors_df)\n",
    "\n",
    "# Calculate the percentage of \"major errors\"\n",
    "percentage_major_errors = (number_major_errors / total_entries) * 100\n",
    "\n",
    "# Display the percentage of \"major errors\"\n",
    "print(f\"The percentage of 'major errors' is {percentage_major_errors:.2f}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-listing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
